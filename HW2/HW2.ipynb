{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "skeleton.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VP8FWGeTq7lD",
        "outputId": "9da76035-55d6-4cd3-9c21-3fa3b57130e9"
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.5.1)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywgrgE-zp_-b"
      },
      "source": [
        "from transformers import BertTokenizer,BertModel\n",
        "import torch\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#bert = BertModel.from_pretrained('dmis-lab/biobert-large-cased-v1.1')\n",
        "#tokenizer = BertTokenizer.from_pretrained('dmis-lab/biobert-large-cased-v1.1')\n",
        "\n",
        "bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "embedding_dim = bert.config.to_dict()['hidden_size']\n",
        "\n",
        "## YOU MAY CHANGE THESE HYPERPARAMETERS\n",
        "LABEL_NUM = 5\n",
        "BATCH_SIZE = 32 #16\n",
        "LEARNING_RATE = 5e-5 #1e-5\n",
        "DROPOUT_RATIO = 0.2\n",
        "MAX_EPOCH = 5\n",
        "TEST_TRAIN_RATIO = 0.3\n",
        "MAX_LEN = 256\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQf5fRPvp_-d"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Lxvt2xsGp_-d",
        "outputId": "2e2aa8ca-3002-4847-94e5-6fe17dc13387"
      },
      "source": [
        "## if you want to use TPU on Colab, run this code\n",
        "\n",
        "!pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.8.1-cp37-cp37m-linux_x86_64.whl\n",
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm\n",
        "\n",
        "device = xm.xla_device()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting cloud-tpu-client==0.10\n",
            "  Downloading https://files.pythonhosted.org/packages/56/9f/7b1958c2886db06feb5de5b2c191096f9e619914b6c31fdf93999fdbbd8b/cloud_tpu_client-0.10-py3-none-any.whl\n",
            "Collecting torch-xla==1.8.1\n",
            "\u001b[?25l  Downloading https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.8.1-cp37-cp37m-linux_x86_64.whl (145.0MB)\n",
            "\u001b[K     |█████████                       | 41.2MB 47.1MB/s eta 0:00:03\u001b[31mERROR: Exception:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/base_command.py\", line 153, in _main\n",
            "    status = self.run(options, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/commands/install.py\", line 382, in run\n",
            "    resolver.resolve(requirement_set)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/legacy_resolve.py\", line 201, in resolve\n",
            "    self._resolve_one(requirement_set, req)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/legacy_resolve.py\", line 365, in _resolve_one\n",
            "    abstract_dist = self._get_abstract_dist_for(req_to_install)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/legacy_resolve.py\", line 313, in _get_abstract_dist_for\n",
            "    req, self.session, self.finder, self.require_hashes\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/operations/prepare.py\", line 194, in prepare_linked_requirement\n",
            "    progress_bar=self.progress_bar\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/download.py\", line 465, in unpack_url\n",
            "    progress_bar=progress_bar\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/download.py\", line 316, in unpack_http_url\n",
            "    progress_bar)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/download.py\", line 551, in _download_http_url\n",
            "    _download_url(resp, link, content_file, hashes, progress_bar)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/download.py\", line 255, in _download_url\n",
            "    consume(downloaded_chunks)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/utils/misc.py\", line 641, in consume\n",
            "    deque(iterator, maxlen=0)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/download.py\", line 223, in written_chunks\n",
            "    for chunk in chunks:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/utils/ui.py\", line 162, in iter\n",
            "    self.next(n)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/progress/__init__.py\", line 120, in next\n",
            "    self.update()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/progress/bar.py\", line 83, in update\n",
            "    self.writeln(line)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/progress/__init__.py\", line 101, in writeln\n",
            "    self.clearln()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/progress/__init__.py\", line 90, in clearln\n",
            "    print('\\r\\x1b[K', end='', file=self.file)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/utils/ui.py\", line 118, in handle_sigint\n",
            "    self.finish()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/utils/ui.py\", line 108, in finish\n",
            "    super(InterruptibleMixin, self).finish()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/progress/__init__.py\", line 107, in finish\n",
            "    print(file=self.file)\n",
            "RuntimeError: reentrant call inside <_io.BufferedWriter name='<stdout>'>\u001b[0m\n",
            "\u001b[K"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-92d20e135ded>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.8.1-cp37-cp37m-linux_x86_64.whl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_xla\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_xla\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxla_model\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch_xla'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ofs9WzQp_-e"
      },
      "source": [
        "text_data = pd.read_csv('train.dat', sep = '\\t', header=None)\n",
        "df_train, df_test = train_test_split(text_data, test_size=TEST_TRAIN_RATIO)\n",
        "df_train.reset_index(drop=True, inplace = True)\n",
        "df_test.reset_index(drop=True, inplace = True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyBqT1ovp_-e"
      },
      "source": [
        "## Prepare Dataset for BERT\n",
        "\n",
        "### TODO : Preprocess input data\n",
        "\n",
        "#### example : when maximum length is 8\n",
        "\n",
        "- original input sentence - \"I really love you\"\n",
        "- tokenizing (use ``bert_tokenizer.tokenize``) -  ['i', 'really', 'love', 'you']\n",
        "- Add special token - ['[CLS]' 'i', 'really', 'love', 'you', '[SEP]'] (length = 6)\n",
        "- Add padding tokens to fit maximum length - ['[CLS]' 'i', 'really', 'love', 'you', '[SEP]', '[PAD]','[PAD]']\n",
        "- Convert tokens to id (use ``bert_tokenizer.convert_tokens_to_ids``)\n",
        "- make attention mask to tell which token is a padding token - [1,1,1,1,1,1,0,0]\n",
        "\n",
        "You may choose other way (even simpler) to preprocess the input text. see https://huggingface.co/transformers/main_classes/tokenizer.html#transformers.PreTrainedTokenizer or https://huggingface.co/transformers/model_doc/bert.html#berttokenizer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzP_HqwMp_-e"
      },
      "source": [
        "class ClinicalDataset(Dataset):\n",
        "\n",
        "    def __init__(self, dataframe, maxlen, tokenizer):\n",
        "\n",
        "        self.df = dataframe.rename(columns={0: \"label\", 1: \"text\"})\n",
        "        #Initialize the BERT tokenizer\n",
        "        self.tokenizer = tokenizer\n",
        "        \n",
        "        self.df['label'] = self.df['label'].apply(lambda x : x-1)\n",
        "\n",
        "        self.maxlen = maxlen\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        #Selecting the sentence and label at the specified index in the data frame\n",
        "        sentence = self.df.loc[index, 'text']\n",
        "        label = self.df.loc[index, 'label']\n",
        "\n",
        "        ##TODO \n",
        "        #Preprocessing the text to be suitable for BERT\n",
        "        tokens = self.tokenizer.tokenize(sentence) \n",
        "        tokens = ['[CLS]'] + tokens + ['[SEP]']\n",
        "        if len(tokens) < self.maxlen:\n",
        "            tokens = tokens + ['[PAD]' for _ in range(self.maxlen - len(tokens))]\n",
        "        else:\n",
        "            tokens = tokens[:self.maxlen-1] + ['[SEP]']\n",
        "\n",
        "        tokens_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
        "        sequence = torch.tensor(tokens_ids)\n",
        "\n",
        "        attention_mask = (sequence != 0).long()\n",
        "\n",
        "        return sequence, attention_mask, label"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9a0lwlwp_-f",
        "outputId": "6c7ddd0c-de09-4daf-a8d1-32673f2653f6"
      },
      "source": [
        "#Creating instances of training and validation set\n",
        "train_set = ClinicalDataset(df_train, maxlen = MAX_LEN,tokenizer = bert_tokenizer)\n",
        "val_set = ClinicalDataset(df_test, maxlen = MAX_LEN,tokenizer = bert_tokenizer)\n",
        "\n",
        "#Creating intsances of training and validation dataloaders\n",
        "train_loader = DataLoader(train_set, batch_size = BATCH_SIZE, num_workers = 2)\n",
        "val_loader = DataLoader(val_set, batch_size = BATCH_SIZE, num_workers = 2)\n",
        "batch = next(iter(train_loader))\n",
        "print(batch)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[tensor([[  101, 18834,  7277,  ...,     0,     0,     0],\n",
            "        [  101,  8040,  3917,  ...,     0,     0,     0],\n",
            "        [  101,  7490, 26721,  ...,  2001,  6560,   102],\n",
            "        ...,\n",
            "        [  101, 14978,  1012,  ...,     0,     0,     0],\n",
            "        [  101,  3276,  1997,  ...,  2558,  1997,   102],\n",
            "        [  101,  2026, 18349,  ...,  5001,  1010,   102]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 1, 1, 1],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 1, 1, 1],\n",
            "        [1, 1, 1,  ..., 1, 1, 1]]), tensor([3, 3, 2, 4, 0, 4, 4, 1, 4, 0, 0, 2, 3, 4, 0, 4, 2, 0, 3, 1, 4, 4, 4, 1,\n",
            "        4, 2, 3, 1, 4, 2, 4, 0])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWCtj9yIp_-f"
      },
      "source": [
        "## Define Neural Network\n",
        "\n",
        "### TODO : Define layers and data flow \n",
        "\n",
        "``nn.Dropout`` could be used to prevent overffiting. (parameter : dropout ratio)\n",
        "\n",
        "from ``bert.config.to_dict()['hidden_size']``, we can obtain size of embedding vector used in pretrained BERT model.\n",
        "\n",
        "Here is information about pytorch functions that used for layers (e.g. ``nn.Linear``):\n",
        "https://pytorch.org/docs/stable/nn.html\n",
        "\n",
        "Here is more information about BERT model implementation on PyTorch : https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpkDWya7p_-f"
      },
      "source": [
        "class Classifier(nn.Module):\n",
        "\n",
        "    def __init__(self,bert,output_len,dropout):\n",
        "        super(Classifier, self).__init__()\n",
        "        ##TODO\n",
        "        #print(bert.config.to_dict()['hidden_size']) 768\n",
        "        ## Define Layers\n",
        "\n",
        "        #Instantiating BERT model object\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "        #Drop out\n",
        "        self.pre_classifier = nn.Linear(768, 768)\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "\n",
        "        #Classification layer\n",
        "        self.cls_layer = nn.Linear(768, output_len)\n",
        "        \n",
        "\n",
        "    def forward(self, sequence, attention_masks):\n",
        "\n",
        "        ##TODO\n",
        "        ##Define data flow in neural network\n",
        "        cont_reps = self.bert(sequence, attention_mask = attention_masks)\n",
        "        cls_rep = cont_reps[0][:, 0]\n",
        "        pre_cls = self.pre_classifier(cls_rep)\n",
        "        drop_out = self.drop(pre_cls)\n",
        "        logits = self.cls_layer(drop_out)\n",
        "        \n",
        "        return logits\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nBuk2Ebp_-g"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "#device = torch.device('cpu')\n",
        "net = Classifier(bert,LABEL_NUM,DROPOUT_RATIO)\n",
        "net.to(device)\n",
        "optimizer = optim.Adam(net.parameters(), lr = LEARNING_RATE)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ca5hf60up_-g"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNn6_wCwp_-g"
      },
      "source": [
        "def get_accuracy(output, labels):\n",
        "\n",
        "    _, pred = torch.max(output.data, axis=1)\n",
        "    ans = (pred == labels.squeeze()).sum()\n",
        "    \n",
        "    return ans\n",
        "\n",
        "def evaluate(net, criterion, dataloader):\n",
        "    net.eval()\n",
        "\n",
        "    mean_acc, mean_loss = 0, 0\n",
        "    count = 0\n",
        "    ans = 0\n",
        "    total_num = 0\n",
        "    \n",
        "\n",
        "    with torch.no_grad():\n",
        "        for seq, attn_masks, labels in dataloader:\n",
        "            seq, attn_masks, labels = seq.to(device), attn_masks.to(device), labels.to(device)\n",
        "            output = net(seq, attn_masks)\n",
        "            mean_loss += criterion(output.squeeze(-1), labels.long()).item()\n",
        "            \n",
        "            ans += get_accuracy(output, labels)\n",
        "            total_num += labels.size(0)\n",
        "            count += 1\n",
        "\n",
        "\n",
        "    return float(ans) / float(total_num), mean_loss / count\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbqtgl0Up_-h"
      },
      "source": [
        "def train(net, criterion, optimizer, dataloader):\n",
        "    \n",
        "    total_loss = 0\n",
        "    count = 0\n",
        "    ans = 0\n",
        "    total_num = 0\n",
        "    net.train()\n",
        "        \n",
        "    for i, (sequence, attention_mask, labels) in enumerate(dataloader):\n",
        "        \n",
        "        \n",
        "        optimizer.zero_grad()  \n",
        "        \n",
        "        sequence, attention_mask, labels = sequence.to(device), attention_mask.to(device), labels.to(device)\n",
        "        \n",
        "        output = net(sequence, attention_mask)\n",
        "        \n",
        "        loss = criterion(output.squeeze(-1), labels.long())\n",
        "        \n",
        "        ##loss.backward() calculate gradients of each parameters\n",
        "        loss.backward()\n",
        "        \n",
        "        ##optimizer.step() updates learnable parameters in the NN using calculated gradients\n",
        "        optimizer.step()\n",
        "        #xm.optimizer_step(optimizer, barrier=True)\n",
        "        \n",
        "        total_loss += criterion(output.squeeze(-1), labels.long()).item()\n",
        "        ans += get_accuracy(output, labels)\n",
        "        total_num += labels.size(0)\n",
        "        count += 1\n",
        "        acc = float(ans)/ float(total_num)\n",
        "        mean_loss = float(total_loss/count)  \n",
        "\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print(\"Iteration {} complete. Loss : {} Accuracy : {}\".format(i+1, mean_loss, acc))\n",
        "     \n",
        "    return acc, mean_loss\n",
        "    \n",
        "  "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbINAQnkp_-h",
        "outputId": "743045df-bfba-4bc7-a3d1-aa22dbb82293"
      },
      "source": [
        "train_acc_list = []\n",
        "train_loss_list = []\n",
        "\n",
        "test_acc_list = []\n",
        "test_loss_list = []\n",
        "for epoch in range(MAX_EPOCH):\n",
        "    train_acc, train_loss = train(net,criterion,optimizer,train_loader)\n",
        "    test_acc, test_loss = evaluate(net,criterion,val_loader)\n",
        "    print(\"Epoch {} complete! Validation Loss : {} Validation Accuracy : {}\".format(epoch+1,test_loss,test_acc))\n",
        "    \n",
        "    train_acc_list.append(train_acc)\n",
        "    train_loss_list.append(train_loss)\n",
        "    \n",
        "    test_acc_list.append(test_acc)\n",
        "    test_loss_list.append(test_loss)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 100 complete. Loss : 1.1809767013788224 Accuracy : 0.5084375\n",
            "Iteration 200 complete. Loss : 1.0672844737768172 Accuracy : 0.5571875\n",
            "Iteration 300 complete. Loss : 1.0237632677952448 Accuracy : 0.5758333333333333\n",
            "Epoch 1 complete! Validation Loss : 0.9267019318307147 Validation Accuracy : 0.6048014773776547\n",
            "Iteration 100 complete. Loss : 0.843471406698227 Accuracy : 0.6459375\n",
            "Iteration 200 complete. Loss : 0.8145121014118195 Accuracy : 0.65765625\n",
            "Iteration 300 complete. Loss : 0.8067869098981222 Accuracy : 0.6611458333333333\n",
            "Epoch 2 complete! Validation Loss : 0.9139856954707819 Validation Accuracy : 0.6128808864265928\n",
            "Iteration 100 complete. Loss : 0.7195934364199639 Accuracy : 0.6959375\n",
            "Iteration 200 complete. Loss : 0.7037405353784562 Accuracy : 0.7040625\n",
            "Iteration 300 complete. Loss : 0.7002060651779175 Accuracy : 0.7032291666666667\n",
            "Epoch 3 complete! Validation Loss : 0.9987528192646363 Validation Accuracy : 0.5881809787626963\n",
            "Iteration 100 complete. Loss : 0.6312987667322159 Accuracy : 0.7334375\n",
            "Iteration 200 complete. Loss : 0.6041088435053825 Accuracy : 0.745625\n",
            "Iteration 300 complete. Loss : 0.6003007231156031 Accuracy : 0.745\n",
            "Epoch 4 complete! Validation Loss : 1.065170802614268 Validation Accuracy : 0.5888734995383195\n",
            "Iteration 100 complete. Loss : 0.5579702597856522 Accuracy : 0.7615625\n",
            "Iteration 200 complete. Loss : 0.5310197387635708 Accuracy : 0.7778125\n",
            "Iteration 300 complete. Loss : 0.5302727480729421 Accuracy : 0.7775\n",
            "Epoch 5 complete! Validation Loss : 1.1397757766877903 Validation Accuracy : 0.5738688827331486\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "zNEkXggDp_-h",
        "outputId": "601bc486-68c5-413e-ac22-0f08e3b6f6f4"
      },
      "source": [
        "x = np.arange(1,MAX_EPOCH+1,1)\n",
        "\n",
        "plt.plot(x,train_acc_list)\n",
        "plt.plot(x,test_acc_list)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fc7e87529d0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}